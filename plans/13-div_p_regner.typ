#import "@preview/cetz:0.3.0"
#import "@preview/syntree:0.2.1": tree
#import "@preview/lovelace:0.3.0": *
#import "@preview/codly:1.1.1": *
#import "@preview/codly-languages:0.1.1": *

#import "../utils.typtp": *
#import "lecon_tplt.typtp": lecon

#show: codly-init.with()
#show: lecon.with(
  titre: [Le√ßon 13 : Algorithmes utilisant la m√©thode ‚â™ diviser pour r√©gner ‚â´. Exemples et applications.], 
  niveau: [Terminal, MP2I, MPI], 
  prerequis: [Compl√©xit√©, R√©cursion, Arbre],
  motivations: [D√©composer un probl√®me en sous probl√®me plus simple pour le r√©soudre plus efficacement])
\

= Pr√©sentation et m√©thodes
#def("Diviser pour r√©gner")[
  Diviser pour r√©gner s'effectue en trois √©tapes :
  - Diviser : cette √©tape d√©compose le probl√®me initial en un ou plusieurs sous-probl√®mes de plus petites tailles
  - R√©gner : chaque sous-probl√®me est r√©solu
  - Rassembler : les solutions des sous-probl√®mes sont rassembl√©es pour construire la solution du probl√®me initial
]

#blk1("M√©thode", "Calcul de complexit√©")[
  Trouver une fonction donnant la taille du probl√®me (ex : le nombre d'√©l√©ment d'une liste). D√©finir C comme la compl√©xit√© maximale des instances de cette taille, puis √©tablir une relation de r√©currence sur C de la forme $C(n) = a times C(f(n))+g(n)$
]

#blk1("Outil", "R√©soudre la relation de r√©currence")[
  - Conjecturer la solution, majorer
  - changement de variable \
    (ex : $C(n)=2C(sqrt(n))+log(n)$ avec $n=2^m$ on a $C(2^m)=S(m)=2S(n/2)+n$)
  - arbre r√©cursif : "d√©pliage" des appels r√©cursifs
]

= Applications √† des listes de donn√©es
== Recherche dichotomique

#blk2("Probl√®me")[
  Recherche un √©l√©ment x dans une liste L tri√©e dans l'ordre croissant.
]

#blk3("Algorithme")[
  Entr√©es : t liste tri√©, x entier, $0 <= g <= d <= "len"(t)$ \
  Sortie : renvoie une position de x dans t[g..d]
  #pseudocode-list(hooks: .5em, booktabs: true)[
    *Recherche(t, x, g, d):*
    + *Si* g > d :
      + *Renvoyer* None
    + m = (a+b)/2
    + *Si* t[m] < x:
      + *Retourner* Recherche(t, x, m+1, d)
    + *Si* E[m] > x:
      + *Retourner* Recherche(t, x, g, m-1)
    + *Sinon*:
      + *Renvoyer* m
  ]
  #pseudocode-list(hooks: .5em, booktabs: true)[
    *Recherche_dichotomique(t, x):*
    + *Retourner* Recherche(t, x, 0, len(t)-1)
  ]
]

#blk2("Compl√©xit√©")[
  $
    C(n)&=C(n/2)+1\
    &= O(log(n))
  $
]

#blk2("Exercice")[
  √âcrire une version it√©rative de cet algorithme.
]

== Tri fusion

#blk2("Probl√®me")[
  Trier une liste L de n √©l√©ments.
]

#blk3("Algorithme")[
  #pseudocode-list(hooks: .5em, booktabs: true)[
    *fusion $(L_1,L_2)$*
      + res = tableau de taille $|L_1| + |L_2|$
      + $i = 0$
      + $j = 0$
      + *Tant que* $i < |L_1| "et" j < |L_2| :$
        + *si* $L_1[i] <= L_2[j]$ :
          + res$[i+j]=L_1[i]$
          + $i = i+1$
        + *sinon* 
          + res$[i+j]=L_2[j]$
          + $j = j+1$
      + *Tant que*  $i < |L_1|$ :
        + res$[i+j]=L_1[i]$
        + $i = i+1$
      + *Tant que*  $j < |L_2|$ :
          + res$[i+j]=L_2[j]$
          + $j = j+1$
      + *renvoyer* res
  ]
  #pseudocode-list(hooks: .5em, booktabs: true)[
    *tri_fusion $(L)$*
      + *si* $|L| <= 1$
        + *renvoyer* $L$
      + *sinon* 
        + s = $|L|$/2
        + *renvoyer* fusion $("tri_fusion"(L[s:]), "tri_fusion"(L[:s]))$
  ]
]

#blk2("Compl√©xit√©")[
  $
    C(n)&=2C(n/2)+O(n)\
    &= 2(2(n/4)+O(n))+O(n)\
    &=...\
    &= 2^k C(n/2^k)+k O(n)\
    &= n O(1)+ log(n)O(n) \
    &= O(n log(n))
  $
]

#dev("Correction totale de tri fusion")

= Applications au calcul formel 
== L'exponentiation rapide
#blk2("Probl√®me")[
  Calculer $a^n$
]

#blk3("Algorithme")[
  #pseudocode-list(hooks: .5em, booktabs: true)[
    *Exponentiation (a, n) :*
    + *Si* n = 0 :
      + *Retourner 1*
    + b = Exponentiation(a, n/2)
    + *Si* n mod 2 = 0 :
      + *Retourner* b \* b
    + *Sinon* :
      + *Retourner* a \* b \* b
  ]
]

#blk2("Compl√©xit√©")[
  $
    C(n)&= C(floor(n/2))+O(1)\
    &= O(log(n))
  $
  On a log(n) multiplication au lieu de n pour la version na√Øve.
]

== Multiplication de matrice

#blk2("Probl√®me")[
  La multiplication de deux matrice carr√©e $n times n$ se fait en $O(n¬≥)$ de fa√ßon na√Øve.
  \ L'algorithme de Strassen obtient un produit matriciel en $O(n^log(7))$.
]

#blk1("Algorithme", "Strassen")[
  L'id√©e derri√®re cette algorithme est de r√©duire le nombre de multiplication.
  On transforme le probl√®me en sous probl√®me, en traitant nos matrices par sous bloc de taille $n/2 times n/2$.\
  Prenons deux matrices : 
  $X = mat(A,B;  C,D)$ $Y = mat(E,F;G,H)$\
  On peut ensuite calculer le produit de tel fa√ßon :  \
  $X Y= mat(P_5+P_4-P_2+P_6, P_1+P_2;P_3+P_4, P_1+P_5-P_3-P_7)$\ \ 
  avec:  \
  $P_1 &= A(F-H) P_5 &= (A+D)(E+H)\
  P_2 &= (A+B)H P_6 &= (B-D)(G+H)\
  P_3 &= (C+D)E P_7 &= (A-C)(E+F)\
  P_4 &= D(G-E)
  $
  \
  Avec cet algorithme on arrive √† la formule de compl√©xit√© suivante : \
  $C(n) = 7C(n/N)+O(n¬≤)=O(n^log(7))$
]

= Applications g√©om√©trique

== Points les plus proche dans un plan
#blk2("Probl√®me")[
  √âtant donn√©es $n$ points dans $RR¬≤$, donner la plus petite distance entre deux points.\
]

#blk2("Solutions")[
  Solution na√Øve : on teste tous les couples $O(n¬≤)$\

  Id√©e de l'algorithme : \
  - Diviser le plan en 2 sur $x_m$, P1 et P2 de taille √©gale (√† 1 pr√®s)
  - Trouver r√©cursivement les plus petites distances $d_1 "et" d_2, d_0 = min(d_1,d_2)$
  - Rechercher la plus petite distance dans la bande autour du d√©coupage $[x_m-d_0;x_m+d_0]$
  - Renvoyer le $min(d_0, d_3)$
]

#blk2("Compl√©xit√©")[
  $C(n)=2C(n/2)+O(n)=O(n log(n))$
]


== Arbre K-dimensionnel

#blk2("Probl√®me")[
  Rechercher les ùëò plus proches voisins d'un point dans $RR^K$.¬†\
]
#blk2("Solution")[
  Solution na√Øve : on test la distance pour tout les points : $O(n¬≤)$.\

  Id√©e de l'algorithme :\
  - Construire un arbre binaire de recherche, appel√© arbre K-dimensionnel, qui pour chaque profondeur de l'arbre, diminuer le nombre de point par deux (√† un pr√®s). Chaque profondeur de l'arbre effectue la recherche du point m√©dian $x$ sur une dimension diff√©rente. On a les points inf√©rieurs √† $x$ dans le sous-arbre gauche et les points supp√©rieur dans le sous-arbre droit. Puis on construit r√©cursivement l'arbre en changeant de dimension √† chaque profondeur.
  - Une fois l'arbre K-dimensionnel cr√©√©, on peut rechercher dans l'arbre en partant de la feuille sur laquelle on aurait positionner notre point et en √©largissant pour avoir le nombre de k voisins.
]

#dev[Recherche des k plus proches voisins gr√¢ce aux arbre K-dimensionnel]